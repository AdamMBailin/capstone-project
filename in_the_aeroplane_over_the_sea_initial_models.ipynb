{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My first attempt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`This was my first attempt at using LSTM networks in keras to predict lyrics. I used the lyrics from In the Aeroplane Over the Sea as my data. This initial attempt was not very successful in terms of making a model the outputs lyrics, but it was instrumental to me developing an understanding of LSTM RNNs and how to structure the data for them.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_lyrics(file):\n",
    "    return pd.read_csv(file, sep='|', header=None, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1157: expected 9 fields, saw 10\\nSkipping line 1158: expected 9 fields, saw 10\\nSkipping line 1159: expected 9 fields, saw 10\\nSkipping line 1160: expected 9 fields, saw 10\\nSkipping line 1161: expected 9 fields, saw 10\\nSkipping line 1162: expected 9 fields, saw 10\\nSkipping line 1163: expected 9 fields, saw 10\\nSkipping line 1164: expected 9 fields, saw 10\\nSkipping line 1166: expected 9 fields, saw 17\\nSkipping line 1906: expected 9 fields, saw 10\\nSkipping line 7590: expected 9 fields, saw 10\\nSkipping line 7601: expected 9 fields, saw 89\\nSkipping line 12820: expected 9 fields, saw 15\\nSkipping line 12938: expected 9 fields, saw 51\\nSkipping line 13082: expected 9 fields, saw 14\\n'\n",
      "b'Skipping line 2237: expected 9 fields, saw 10\\n'\n",
      "b'Skipping line 12297: expected 9 fields, saw 19\\nSkipping line 18442: expected 9 fields, saw 11\\n'\n"
     ]
    }
   ],
   "source": [
    "alt_country_df       = read_lyrics('songs/alt_countrysong_lyrics.psv')\n",
    "alt_rock_df          = read_lyrics('songs/alt_rocksong_lyrics.psv')\n",
    "experimental_rock_df = read_lyrics('songs/experimental_rocksong_lyrics.psv')\n",
    "hip_hop_df           = read_lyrics('songs/hip_hipsong_lyrics.psv')\n",
    "pop_songs_df         = read_lyrics('songs/popsong_lyrics.psv')\n",
    "rock_songs_df        = read_lyrics('songs/Rocksong_lyrics.psv')\n",
    "folk = read_lyrics('data/song_lyrics.psv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_dfs = [alt_country_df, alt_rock_df, experimental_rock_df, hip_hop_df, pop_songs_df, rock_songs_df]\n",
    "list_of_names = ['alt_country', 'alt_rock', 'experimental_rock', 'hip_hop', 'pop_songs', 'rock_songs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_genre(cell):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for count, df in enumerate(list_of_dfs):\n",
    "    name = list_of_names[count]\n",
    "    df['is_' + name] = df[3].apply(is_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = list_of_dfs[0]\n",
    "for next_df in list_of_dfs[1:]:\n",
    "    df1 = pd.concat((df1, next_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/api.py:77: RuntimeWarning: '<' not supported between instances of 'int' and 'str', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat((folk, df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('all_songs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [hook] n I've been to a minor place n And I ca...\n",
       "1       Today was one where, lost in thought n I reall...\n",
       "2       Well you're my friend n (That's what you told ...\n",
       "3       I like to have a good time n Any of my friends...\n",
       "4       I am here, right here n Where God puts non asu...\n",
       "5       Fire-burned and blew out flowers n Showing me ...\n",
       "6       Sing a song of madeleine-mary n A tune that al...\n",
       "7       Your little feet n Your sharp teeth n The way ...\n",
       "8       Tonight my eyes were hurting much n As I had s...\n",
       "9       Black, you are my enemy n And I cannot get clo...\n",
       "10      Darling n I can stay awake all night n And I w...\n",
       "11      [Verse 1] n When you were young, you were the ...\n",
       "12      Part Two n [Verse 1] n I love you, Jesus Chris...\n",
       "13      [Verse 1] n What a beautiful face n I have fou...\n",
       "14      [Verse 1] n Two headed boy n All floating in g...\n",
       "15                                         [Instrumental]\n",
       "16      [Verse 1] n The only girl I've ever loved n Wa...\n",
       "17      [Intro] n One n [Verse] n Sweet communist, the...\n",
       "18      [Verse 1] n Oh comely, I will be with you when...\n",
       "19      [Verse 1] n Ghost, ghost, I know you live with...\n",
       "20                                         [Instrumental]\n",
       "21      [Verse 1] n Daddy, please hear this song that ...\n",
       "22      Downtown n My darling dime store thief n In th...\n",
       "23      Rousseau walks on trumpet paths n Safaris to t...\n",
       "24      The big man arrives n Disco dancers greet him ...\n",
       "25      Don't interrupt the sorrow n Darn right n In f...\n",
       "26      Out of the fire like Catholic saints n Comes S...\n",
       "27      He bought her a diamond for her throat n He pu...\n",
       "28      Down in the cellar in the Boho zone n I went l...\n",
       "29      Heatwaves on the runway n As the wheels set do...\n",
       "                              ...                        \n",
       "5912    No one here n Believes in suicide n You can't ...\n",
       "5913    [Spoken:] n You alright? n Hmm n (Foreign lang...\n",
       "5914    [Verse 1] n A soft wise of [?] n In the air ho...\n",
       "5915    [Verse 1] n Ozzie Smith was born on my birthda...\n",
       "5916    [Verse 1] n Driftin’ pairs to my bedroom windo...\n",
       "5917    [Verse 1] n I’ll be with you right up until th...\n",
       "5918                                       [Instrumental]\n",
       "5919                                       [Instrumental]\n",
       "5920                                       [Instrumental]\n",
       "5921    [Chorus] n Behind the airport mirror n Masturb...\n",
       "5922    [Verse 1] n See him through the green field n ...\n",
       "5923    Before you know there’s goes his ghost again n...\n",
       "5924    Don’t tell me ten things that you know n Don’t...\n",
       "5925    Rain came down twelve-oh-one n New Year’s Eve ...\n",
       "5926    What do you want with my heart? n What do you ...\n",
       "5927    Clouds sweep down from the heavens to the whea...\n",
       "5928    This is the last time, this time I know I'm do...\n",
       "5929    [Instrumental] n [Verse 1] n You should blame ...\n",
       "5930    [Chorus] n You have amazing eyes n The right o...\n",
       "5931    Maybe tomorrow the storm will blow over n And ...\n",
       "5932    CHORUS: n That's the last I'll compromise n Be...\n",
       "5933    Walking into the night n I would take nothing ...\n",
       "5934    When you're at the top n You put yourself abov...\n",
       "5935    I look away and you're gone n Less than a day ...\n",
       "5936    How long How long n Can you keep it going? n Y...\n",
       "5937    CHORUS: n If you love me n Don't you let me go...\n",
       "5938    Pain, pain isn't everything n I'm not into suf...\n",
       "5939    I won't be running away n I know how it looks ...\n",
       "5940    Dreaming of her eyes n We pretend there's so m...\n",
       "5941    [Intro] n [Verse 1] n There’s a man at home nu...\n",
       "Name: 7, Length: 5942, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folk[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "longest = 0\n",
    "for line in nmh_lyrics[0]:\n",
    "    if len(line.split()) > longest:\n",
    "        longest = len(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmh_lyrics = pd.read_table('nmh_lyrics.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for line in nmh_lyrics[0]:\n",
    "    x = ((line.lower() + '<eos>').split())\n",
    "    for word in x:\n",
    "        data.append(word)\n",
    "\n",
    "counter = collections.Counter(data)\n",
    "\n",
    "count_paris = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "words, counts = list(zip(*count_paris))\n",
    "\n",
    "word_to_id = dict(zip(words, range(len(words))))\n",
    "\n",
    "word_to_vec = [word_to_id[word] if word in word_to_id else word_to_id['unknown'] for word in data]\n",
    "\n",
    "reverse_dict = dict(zip(range(len(words)), words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_vocab = len(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((n_patterns, seq_length, n_vocab), dtype=np.bool)\n",
    "y = np.zeros((n_patterns, n_vocab), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(dataX):\n",
    "    for t, word in enumerate(sentence):\n",
    "        X[i, t, word] = 1\n",
    "    y[i, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_0 = Sequential()\n",
    "model_0.add(LSTM(512, return_sequences=True, input_shape=(seq_length, n_vocab)))\n",
    "model_0.add(Dropout(0.2))\n",
    "model_0.add(LSTM(512, return_sequences=False))\n",
    "model_0.add(Dropout(0.2))\n",
    "model_0.add(Dense(len(words)))\n",
    "#model.add(Dense(1000))\n",
    "model_0.add(Activation('softmax'))\n",
    "\n",
    "model_0.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2519/2519 [==============================] - 52s 20ms/step - loss: 5.8090\n",
      "Epoch 2/20\n",
      "2519/2519 [==============================] - 48s 19ms/step - loss: 5.4257\n",
      "Epoch 3/20\n",
      "2519/2519 [==============================] - 51s 20ms/step - loss: 5.4018\n",
      "Epoch 4/20\n",
      "2519/2519 [==============================] - 55s 22ms/step - loss: 5.3087\n",
      "Epoch 5/20\n",
      "2519/2519 [==============================] - 49s 19ms/step - loss: 5.2217\n",
      "Epoch 6/20\n",
      "2519/2519 [==============================] - 48s 19ms/step - loss: 5.0233\n",
      "Epoch 7/20\n",
      "2519/2519 [==============================] - 54s 21ms/step - loss: 4.8431\n",
      "Epoch 8/20\n",
      "2519/2519 [==============================] - 49s 19ms/step - loss: 4.7970\n",
      "Epoch 9/20\n",
      "2519/2519 [==============================] - 48s 19ms/step - loss: 4.5731\n",
      "Epoch 10/20\n",
      "2519/2519 [==============================] - 56s 22ms/step - loss: 4.4187\n",
      "Epoch 11/20\n",
      "2519/2519 [==============================] - 51s 20ms/step - loss: 4.2697\n",
      "Epoch 12/20\n",
      "2519/2519 [==============================] - 53s 21ms/step - loss: 4.1347\n",
      "Epoch 13/20\n",
      "2519/2519 [==============================] - 56s 22ms/step - loss: 3.9886\n",
      "Epoch 14/20\n",
      "2519/2519 [==============================] - 61s 24ms/step - loss: 3.8488\n",
      "Epoch 15/20\n",
      "2519/2519 [==============================] - 81s 32ms/step - loss: 3.6922\n",
      "Epoch 16/20\n",
      "2519/2519 [==============================] - 68s 27ms/step - loss: 3.5424\n",
      "Epoch 17/20\n",
      "2519/2519 [==============================] - 66s 26ms/step - loss: 3.3752\n",
      "Epoch 18/20\n",
      "2519/2519 [==============================] - 64s 26ms/step - loss: 3.2330\n",
      "Epoch 19/20\n",
      "2519/2519 [==============================] - 70s 28ms/step - loss: 3.0786\n",
      "Epoch 20/20\n",
      "2519/2519 [==============================] - 74s 30ms/step - loss: 2.9065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ca03dd8>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.fit(X, y, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature \n",
    "    dist = np.exp(a)/np.sum(np.exp(a))\n",
    "    choices = range(len(a))\n",
    "    return np.random.choice(choices, p=dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the life we used to love <eos> just to keep ourselves <eos> at least enough to carry on <eos> [verse\n",
      "[versewillisleftsongsateveryladoallyouryouryouryourwillbodyagoherheraayouyouyouyouyouyouyouyouyouyoui[verseyouyouyouyouyouyousheyouyouiiyouryouryouryourweyouyouthatyouyouyouyouiwillyouryourwilli'mlayallalliyouryourinlalalawho'sheremeforinin[versewillisdo,measyouyou[verseyoudeedeewithdeeshe[versethethetheyourthatboyforyouyouyouwillwillwilldohereasherheryouyouyouyouwill[versewillwould[instrumental]<eos>fetusesdeeiyouryouryouryouraherboymewewithitototototoamyonlyuntilmeher[verseiweawillyouracouldwill[verse[verseyouyouyouawillyouryourbeaparttotothetheyourwill[versetotoyouyouyouyouyouthatthethewillpluckbendwithwith<eos><eos><eos><eos><eos>youryourbeearthboymeininyouryouryouryourawillaherfromsongdoinallallallyouryourwilldon'tleftforwiththethethethethethewillheadleftforall<eos><eos><eos><eos>thatwewouldwouldwouldwhereallallwithyouryour[versewillayouryour[versewassingrosestotothatyouyouyouryouryouryouryourawillwillweweyouryourwillsoagreeawaybeher[verseandandandand[versecouldholecareeningtototoyouyouyouyousheheaaandandyouyouyouyouwillcouldfindyou'reourher[verse[verse[versewillwithwheresototoatototoyouyouyouyouyouyouyouyouyouyouyouyouyouyouyoucouldwillwill[verse[verse[versewillwillcouldyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouwilldeeitonsomeyouyouwithiwithkeeplivewayswith<eos><eos><eos><eos><eos><eos><eos><eos>yourthatthatweyouyouyouyouyouwillyouwilldeescreamswithinwith<eos><eos><eos><eos><eos>toyouwewewewillwilldeeeverydee<eos><eos><eos><eos><eos>youryourkeepboxesofinall<eos><eos><eos><eos><eos>weiswouldkeepallallallalldeelaherselfevertheirsoftdoasherto<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>deedeeyouyouyouyouryourwillyou,insideforyou[verseyouyouyou[verseiwillcouldgreenmyonall<eos><eos><eos><eos>youdon'tsomewrappedgoyouryouryouryourwebornjustofon<eos><eos><eos><eos><eos><eos>webe[verseyoudeeis[versethe[versesoplaceaimedbeautifulheryouyouyouyouwillwillasenoughwithwithyouyouyouyouyouyouyouyouyouyouyouyoudeewethatyouyouyouyouyouyouyouyouyoudeeyouyouii[verse<eos><eos><eos><eos><eos><eos><eos><eos><eos>youryouryourcouldno-onewastotoyouryouryouryourbe1]mewherewithyouryourwillsunagainonyouyouyouyou[versecouldwillyouyouyouyou[versethe[versebeautifulourmeanleftyouiinyouryourtobeflowersinsideononyouryourayoushekeep[verse[verseyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyouyou[verse[versedeesleepmetotowillwillknowwe'llwith<eos><eos><eos><eos><eos><eos>[versecould3]outoutourheryouyouwitha[verseyouyouyouyouis[verseyouyouyouyouyouyouyouyouyouyouyouhercouldwillyouareareyouyouyouyouyou[versewillsomeflowmethattothetheisunaimedfromfromdo,wedeealltowewillweweyouyouwillwillwillsomelalalalaiswith<eos><eos><eos><eos><eos><eos><eos><eos>yourwewillwillsomeacrossuntillahowdeethatyouthatyouryouryourweplayedoutrosesforwithwithwewewekeepbeheryouyouiyouryour[versesomecomely,ourselvesareher[verse[versewillistakebrightforisdeeyouyouyouyouryourweholecomely,foryouyouyouyouryouryouryourwelovedlayformeononwiththatwillwillyouyouyou<eos><eos><eos>yourcouldpushwaitboyfrommei<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>wekeepdooagainweredeeourdeewithiiwithiswereherbutonyou[verse[verse[versewithkeepsheallwithyouryouryourwillsoshe'llrosesmemeyouryouryourwillshoestowardsforwith<eos><eos><eos><eos><eos><eos>youryouryouryourwilluntilwetowithcouldmyburiedoutlaforyouyouyouyou[verse[versecouldsillydo,dee,lamemeallyouyouyou[verse[versewillbeacrosswhere<eos><eos>withyouryourdeedaydeeallalliyourthewillthereneedfromtherearedododoyouyou[versethethethewillmouthwereallallall<eos><eos><eos>"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(word_to_vec) - 1)\n",
    "pattern = word_to_vec[start:start + seq_length]\n",
    "\n",
    "print(' '.join([reverse_dict[x] for x in pattern]))\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.zeros((1, len(pattern), 669))\n",
    "    for c, word in enumerate(pattern):\n",
    "        x[0, c, word] = 1\n",
    "    \n",
    "    prediction = model_0.predict(x, verbose=0)[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    index = sample(prediction, diversity)\n",
    "    \n",
    "    result = reverse_dict[index]\n",
    "    with open('512_hidden_two_LTSM_layers_first_attempt.txt', 'a+') as f:\n",
    "        print(result, file=f)\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 20\n",
    "dataX, dataY = [], []\n",
    "for i in range(0, len(data) - seq_length, 1):\n",
    "    seq_in = word_to_vec[i:i + seq_length]\n",
    "    seq_out = word_to_vec[i + seq_length]\n",
    "    dataX.append(seq_in)\n",
    "    dataY.append(seq_out)\n",
    "n_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "X = X / n_vocab\n",
    "y = to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(TimeDistributed(Dense(669)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2514/2514 [==============================] - 16s 6ms/step - loss: 5.7712 - categorical_accuracy: 0.1289\n",
      "\n",
      "Epoch 00001: loss improved from inf to 5.77121, saving model to weights-improvement-01-5.7712.hdf5\n",
      "Epoch 2/20\n",
      "2514/2514 [==============================] - 16s 6ms/step - loss: 5.4073 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00002: loss improved from 5.77121 to 5.40726, saving model to weights-improvement-02-5.4073.hdf5\n",
      "Epoch 3/20\n",
      "2514/2514 [==============================] - 16s 7ms/step - loss: 5.3686 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00003: loss improved from 5.40726 to 5.36857, saving model to weights-improvement-03-5.3686.hdf5\n",
      "Epoch 4/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3650 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00004: loss improved from 5.36857 to 5.36503, saving model to weights-improvement-04-5.3650.hdf5\n",
      "Epoch 5/20\n",
      "2514/2514 [==============================] - 15s 6ms/step - loss: 5.3575 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00005: loss improved from 5.36503 to 5.35753, saving model to weights-improvement-05-5.3575.hdf5\n",
      "Epoch 6/20\n",
      "2514/2514 [==============================] - 16s 6ms/step - loss: 5.3536 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00006: loss improved from 5.35753 to 5.35360, saving model to weights-improvement-06-5.3536.hdf5\n",
      "Epoch 7/20\n",
      "2514/2514 [==============================] - 16s 6ms/step - loss: 5.3523 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00007: loss improved from 5.35360 to 5.35225, saving model to weights-improvement-07-5.3523.hdf5\n",
      "Epoch 8/20\n",
      "2514/2514 [==============================] - 15s 6ms/step - loss: 5.3503 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00008: loss improved from 5.35225 to 5.35026, saving model to weights-improvement-08-5.3503.hdf5\n",
      "Epoch 9/20\n",
      "2514/2514 [==============================] - 15s 6ms/step - loss: 5.3481 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00009: loss improved from 5.35026 to 5.34811, saving model to weights-improvement-09-5.3481.hdf5\n",
      "Epoch 10/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3439 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00010: loss improved from 5.34811 to 5.34387, saving model to weights-improvement-10-5.3439.hdf5\n",
      "Epoch 11/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3424 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00011: loss improved from 5.34387 to 5.34239, saving model to weights-improvement-11-5.3424.hdf5\n",
      "Epoch 12/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3426 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00012: loss did not improve\n",
      "Epoch 13/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3411 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00013: loss improved from 5.34239 to 5.34110, saving model to weights-improvement-13-5.3411.hdf5\n",
      "Epoch 14/20\n",
      "2514/2514 [==============================] - 15s 6ms/step - loss: 5.3350 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00014: loss improved from 5.34110 to 5.33503, saving model to weights-improvement-14-5.3350.hdf5\n",
      "Epoch 15/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3372 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00015: loss did not improve\n",
      "Epoch 16/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3302 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00016: loss improved from 5.33503 to 5.33017, saving model to weights-improvement-16-5.3302.hdf5\n",
      "Epoch 17/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3283 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00017: loss improved from 5.33017 to 5.32835, saving model to weights-improvement-17-5.3283.hdf5\n",
      "Epoch 18/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3247 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00018: loss improved from 5.32835 to 5.32468, saving model to weights-improvement-18-5.3247.hdf5\n",
      "Epoch 19/20\n",
      "2514/2514 [==============================] - 15s 6ms/step - loss: 5.3207 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00019: loss improved from 5.32468 to 5.32069, saving model to weights-improvement-19-5.3207.hdf5\n",
      "Epoch 20/20\n",
      "2514/2514 [==============================] - 14s 6ms/step - loss: 5.3112 - categorical_accuracy: 0.1313\n",
      "\n",
      "Epoch 00020: loss improved from 5.32069 to 5.31119, saving model to weights-improvement-20-5.3112.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1491f4da0>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(dataX) - 1)\n",
    "pattern = dataX[start]\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x/669\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = reverse_dict[index]\n",
    "#     with open('fourth_attempt.txt', 'a+') as f:\n",
    "#         print(result, file=f)\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 6.5098 - categorical_accuracy: 3.9386e-04\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 6.4637 - categorical_accuracy: 0.0087\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 6.4146 - categorical_accuracy: 0.1315\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 6.3596 - categorical_accuracy: 0.1315\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 6.2979 - categorical_accuracy: 0.1315\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 6.2310 - categorical_accuracy: 0.1315\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 6.1612 - categorical_accuracy: 0.1315\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 6.0902 - categorical_accuracy: 0.1315\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 6.0194 - categorical_accuracy: 0.1315\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.9490 - categorical_accuracy: 0.1315\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.8793 - categorical_accuracy: 0.1315\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.8110 - categorical_accuracy: 0.1315\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.7437 - categorical_accuracy: 0.1315\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.6772 - categorical_accuracy: 0.1315\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.6119 - categorical_accuracy: 0.1315\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.5493 - categorical_accuracy: 0.1315\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.4914 - categorical_accuracy: 0.1315\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.4411 - categorical_accuracy: 0.1315\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.4012 - categorical_accuracy: 0.1315\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.3724 - categorical_accuracy: 0.1315\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 5.3544 - categorical_accuracy: 0.1315\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 19s 19s/step - loss: 5.3452 - categorical_accuracy: 0.1315\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.3414 - categorical_accuracy: 0.1315\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.3402 - categorical_accuracy: 0.1315\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.3394 - categorical_accuracy: 0.1315\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.3381 - categorical_accuracy: 0.1315\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 5.3359 - categorical_accuracy: 0.1315\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 5.3329 - categorical_accuracy: 0.1315\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.3294 - categorical_accuracy: 0.1315\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.3258 - categorical_accuracy: 0.1315\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.3223 - categorical_accuracy: 0.1315\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 19s 19s/step - loss: 5.3190 - categorical_accuracy: 0.1315\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 19s 19s/step - loss: 5.3161 - categorical_accuracy: 0.1315\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 21s 21s/step - loss: 5.3137 - categorical_accuracy: 0.1315\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 5.3115 - categorical_accuracy: 0.1315\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.3097 - categorical_accuracy: 0.1315\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.3081 - categorical_accuracy: 0.1315\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.3067 - categorical_accuracy: 0.1315\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.3053 - categorical_accuracy: 0.1315\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.3039 - categorical_accuracy: 0.1315\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.3024 - categorical_accuracy: 0.1315\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.3008 - categorical_accuracy: 0.1315\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2992 - categorical_accuracy: 0.1315\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2976 - categorical_accuracy: 0.1315\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2959 - categorical_accuracy: 0.1315\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2942 - categorical_accuracy: 0.1315\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2924 - categorical_accuracy: 0.1315\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2907 - categorical_accuracy: 0.1315\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2892 - categorical_accuracy: 0.1315\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2879 - categorical_accuracy: 0.1315\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2866 - categorical_accuracy: 0.1315\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2848 - categorical_accuracy: 0.1315\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2831 - categorical_accuracy: 0.1315\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2813 - categorical_accuracy: 0.1315\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2797 - categorical_accuracy: 0.1315\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2780 - categorical_accuracy: 0.1315\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 5.2762 - categorical_accuracy: 0.1315\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2743 - categorical_accuracy: 0.1315\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2721 - categorical_accuracy: 0.1315\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2696 - categorical_accuracy: 0.1315\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2673 - categorical_accuracy: 0.1315\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2649 - categorical_accuracy: 0.1315\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2622 - categorical_accuracy: 0.1315\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2592 - categorical_accuracy: 0.1315\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2564 - categorical_accuracy: 0.1315\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2534 - categorical_accuracy: 0.1315\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2501 - categorical_accuracy: 0.1315\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2470 - categorical_accuracy: 0.1315\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2438 - categorical_accuracy: 0.1315\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2403 - categorical_accuracy: 0.1315\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2367 - categorical_accuracy: 0.1315\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2329 - categorical_accuracy: 0.1315\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2291 - categorical_accuracy: 0.1315\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2253 - categorical_accuracy: 0.1315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2214 - categorical_accuracy: 0.1315\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.2174 - categorical_accuracy: 0.1315\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2131 - categorical_accuracy: 0.1315\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 5.2086 - categorical_accuracy: 0.1315\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.2040 - categorical_accuracy: 0.1315\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.1992 - categorical_accuracy: 0.1315\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1942 - categorical_accuracy: 0.1315\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1892 - categorical_accuracy: 0.1315\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.1840 - categorical_accuracy: 0.1315\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.1787 - categorical_accuracy: 0.1315\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1734 - categorical_accuracy: 0.1315\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1682 - categorical_accuracy: 0.1315\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1630 - categorical_accuracy: 0.1315\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1578 - categorical_accuracy: 0.1315\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.1526 - categorical_accuracy: 0.1315\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.1474 - categorical_accuracy: 0.1315\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1423 - categorical_accuracy: 0.1315\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1372 - categorical_accuracy: 0.1315\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.1321 - categorical_accuracy: 0.1315\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.1269 - categorical_accuracy: 0.1315\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1217 - categorical_accuracy: 0.1315\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1165 - categorical_accuracy: 0.1315\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 5.1112 - categorical_accuracy: 0.1315\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.1059 - categorical_accuracy: 0.1406\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 5.1008 - categorical_accuracy: 0.1430\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.0958 - categorical_accuracy: 0.1442\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['song_id', 'album_id', 'artist', 'album', 'album_href', 'song', 'track_count', 'lyrics',\n",
    "              'song_href', 'is_folk', 'is_folk_rock', 'is_indie_folk', 'is_alt_country', 'is_alt_rock',\n",
    "              'is_experimental_rock', 'is_hip_hop', 'is_pop_songs', 'is_rock_songs']\n",
    "\n",
    "df['song_id'] = df.index\n",
    "\n",
    "df.to_csv('all_songs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
