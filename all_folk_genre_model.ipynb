{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all folk songs and a complete pipline to create a genre level model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Here, I took what I learned from making the album and artist level models and applied it to all folk songs in a dataset. I wrote a series of functions that load the data, clean it, and transform it into a ready format for the neural network. These functions can be chained together to load any group of songs from my data set and start training a neural network on the lyrics. This notebook in has pip install cells so that it can be run on an AWS instance.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (48.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 48.0MB 17kB/s  eta 0:00:01    35% |███████████▎                    | 17.0MB 48.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading grpcio-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (7.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.5MB 108kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading gast-0.2.0.tar.gz\n",
      "Collecting numpy>=1.13.3 (from tensorflow)\n",
      "  Downloading numpy-1.14.2-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.2MB 67kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading astor-0.6.2-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.8.0,>=1.7.0 (from tensorflow)\n",
      "  Downloading tensorboard-1.7.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 262kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.1.6 (from tensorflow)\n",
      "  Downloading absl-py-0.1.13.tar.gz (80kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 7.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow)\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
      "  Downloading Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 2.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
      "  Downloading Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 7.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bleach==1.5.0 (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
      "  Downloading bleach-1.5.0-py2.py3-none-any.whl\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
      "  Downloading html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K    100% |████████████████████████████████| 890kB 919kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gast, absl-py, termcolor, html5lib\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/8e/fa/d6/77dd17d18ea23fd7b860e02623d27c1be451521af40dd4a13e\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/76/f7/0c/88796d7212af59bb2f496b12267e0605f205170781e9b86479\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/de/f7/bf/1bcac7bf30549e6a4957382e2ecab04c88e513117207067b03\n",
      "  Running setup.py bdist_wheel for html5lib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/6f/85/6c/56b8e1292c6214c4eb73b9dda50f53e8e977bf65989373c962\n",
      "Successfully built gast absl-py termcolor html5lib\n",
      "Installing collected packages: grpcio, gast, numpy, astor, werkzeug, markdown, html5lib, bleach, tensorboard, absl-py, termcolor, tensorflow\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: html5lib 1.0.1\n",
      "    Uninstalling html5lib-1.0.1:\n",
      "      Successfully uninstalled html5lib-1.0.1\n",
      "  Found existing installation: bleach 2.1.3\n",
      "    Uninstalling bleach-2.1.3:\n",
      "      Successfully uninstalled bleach-2.1.3\n",
      "Successfully installed absl-py-0.1.13 astor-0.6.2 bleach-1.5.0 gast-0.2.0 grpcio-1.10.0 html5lib-0.9999999 markdown-2.6.11 numpy-1.14.2 tensorboard-1.7.0 tensorflow-1.7.0 termcolor-1.1.0 werkzeug-0.14.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
      "\u001b[K    100% |████████████████████████████████| 337kB 1.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.1.5\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.2.5.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 634kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/18/9c/1f/276bc3f421614062468cb1c9d695e6086d0c73d67ea363c501\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.2.5\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import collections\n",
    "from nltk.corpus import words\n",
    "from scipy import sparse\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = 'model_chekpoints/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename='all_songs.csv', col='album', col_value='In the Aeroplane Over the Sea'):\n",
    "    df    = pd.read_csv('all_songs.csv')\n",
    "    df    = df.loc[df[col] == col_value]\n",
    "    songs = df['lyrics'].values\n",
    "    return songs\n",
    "\n",
    "def lyric_cleaner(songs):\n",
    "    lyric_tokens = []\n",
    "    for song in songs:\n",
    "        text = song.lower().replace(' n ', ' eol ').replace('[verse ', '[verse')\n",
    "        text = text.replace(\"'\", '').replace('-', ' ')\n",
    "        tokens = text.split()\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        tokens = [word.translate(table) for word in tokens]\n",
    "        lyric_tokens.append(tokens)\n",
    "    return lyric_tokens\n",
    "\n",
    "def lyric_gatherer(lyric_tokens):\n",
    "    lyrics = []\n",
    "    for song in lyric_tokens:\n",
    "        song.append('eos')\n",
    "        for lyric in song:\n",
    "            lyrics.append(lyric)   \n",
    "    return lyrics\n",
    "\n",
    "def vocabulary_dictionary(lyrics, n_vocab):\n",
    "    word_count = collections.Counter(lyrics)\n",
    "    most_common = word_count.most_common(n=n_vocab)\n",
    "    vocab = []\n",
    "    for word, count in most_common:\n",
    "        vocab.append(word)\n",
    "    word_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "    word_to_index['unknown'] = len(vocab)\n",
    "    index_to_word = dict([(index, word) for word, index in word_to_index.items()])\n",
    "    return word_to_index, index_to_word\n",
    "\n",
    "def tokenizer(dictionary, lyrics):\n",
    "    encoded_lyrics = [dictionary[lyric] if lyric in dictionary else dictionary['unknown'] for lyric in lyrics]\n",
    "    return encoded_lyrics\n",
    "\n",
    "def sequenizer(encoded_lyrics, seq_length):\n",
    "    length = seq_length + 1\n",
    "    sequences = []\n",
    "    for i in range(length, len(encoded_lyrics)):\n",
    "        sequence = encoded_lyrics[i-length:i]\n",
    "        sequences.append(sequence)\n",
    "    n_patterns = len(sequences)\n",
    "    sequences = np.array(sequences)\n",
    "    return sequences, n_patterns\n",
    "    \n",
    "def prepare_data(sequences):\n",
    "    X, y = sequences[:, :-1], sequences[:, -1]\n",
    "#     y = to_categorical(y)\n",
    "    return X, y\n",
    "\n",
    "def prepare_model(vocab_size, seq_length, lstm_hidden_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "    model.add(LSTM(lstm_hidden_size, return_sequences=True))\n",
    "    model.add(LSTM(lstm_hidden_size, return_sequences=False))\n",
    "    model.add(Dense(lstm_hidden_size, activation='relu'))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 20\n",
    "n_vocab = 10000\n",
    "vocab_size = n_vocab + 1\n",
    "lstm_hidden_size = 50\n",
    "\n",
    "data         = load_data(filename='all_songs.csv', col='is_folk', col_value=1)\n",
    "\n",
    "lyric_tokens = lyric_cleaner(data)\n",
    "\n",
    "lyrics       = lyric_gatherer(lyric_tokens)\n",
    "\n",
    "word_to_index, index_to_word = vocabulary_dictionary(lyrics, n_vocab)\n",
    "\n",
    "encoded_lyrics = tokenizer(word_to_index, lyrics)\n",
    "\n",
    "sequences, n_patterns = sequenizer(encoded_lyrics, seq_length)\n",
    "\n",
    "X, y = prepare_data(sequences)\n",
    "\n",
    "model = prepare_model(vocab_size, seq_length, lstm_hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, train_size=0.5, random_state=2018)\n",
    "\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "548030/548030 [==============================] - 350s 638us/step - loss: 5.6964 - acc: 0.1522\n",
      "\n",
      "Epoch 00001: loss improved from inf to 5.69642, saving model to model_chekpoints/weights-improvement-01-5.6964.hdf5\n",
      "Epoch 2/100\n",
      "548030/548030 [==============================] - 346s 632us/step - loss: 5.1594 - acc: 0.1925\n",
      "\n",
      "Epoch 00002: loss improved from 5.69642 to 5.15943, saving model to model_chekpoints/weights-improvement-02-5.1594.hdf5\n",
      "Epoch 3/100\n",
      "548030/548030 [==============================] - 346s 632us/step - loss: 4.9407 - acc: 0.2061\n",
      "\n",
      "Epoch 00003: loss improved from 5.15943 to 4.94066, saving model to model_chekpoints/weights-improvement-03-4.9407.hdf5\n",
      "Epoch 4/100\n",
      "548030/548030 [==============================] - 346s 631us/step - loss: 4.8072 - acc: 0.2131\n",
      "\n",
      "Epoch 00004: loss improved from 4.94066 to 4.80716, saving model to model_chekpoints/weights-improvement-04-4.8072.hdf5\n",
      "Epoch 5/100\n",
      "548030/548030 [==============================] - 346s 631us/step - loss: 4.7074 - acc: 0.2189\n",
      "\n",
      "Epoch 00005: loss improved from 4.80716 to 4.70742, saving model to model_chekpoints/weights-improvement-05-4.7074.hdf5\n",
      "Epoch 6/100\n",
      "531456/548030 [============================>.] - ETA: 10s - loss: 4.5641 - acc: 0.2272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 345s 629us/step - loss: 4.5098 - acc: 0.2309\n",
      "\n",
      "Epoch 00008: loss improved from 4.56496 to 4.50977, saving model to model_chekpoints/weights-improvement-08-4.5098.hdf5\n",
      "Epoch 9/100\n",
      "275840/548030 [==============>...............] - ETA: 2:51 - loss: 4.4464 - acc: 0.2350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 345s 629us/step - loss: 4.4159 - acc: 0.2377\n",
      "\n",
      "Epoch 00010: loss improved from 4.46047 to 4.41586, saving model to model_chekpoints/weights-improvement-10-4.4159.hdf5\n",
      "Epoch 11/100\n",
      "101120/548030 [====>.........................] - ETA: 4:41 - loss: 4.3592 - acc: 0.2401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432000/548030 [======================>.......] - ETA: 1:12 - loss: 4.3296 - acc: 0.2449"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 345s 629us/step - loss: 4.3015 - acc: 0.2474\n",
      "\n",
      "Epoch 00013: loss improved from 4.33681 to 4.30154, saving model to model_chekpoints/weights-improvement-13-4.3015.hdf5\n",
      "Epoch 14/100\n",
      "169216/548030 [========>.....................] - ETA: 3:58 - loss: 4.2293 - acc: 0.2522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455936/548030 [=======================>......] - ETA: 57s - loss: 4.2301 - acc: 0.2525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 344s 627us/step - loss: 4.2070 - acc: 0.2545\n",
      "\n",
      "Epoch 00016: loss improved from 4.23636 to 4.20703, saving model to model_chekpoints/weights-improvement-16-4.2070.hdf5\n",
      "Epoch 17/100\n",
      "213760/548030 [==========>...................] - ETA: 3:30 - loss: 4.1471 - acc: 0.2581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481664/548030 [=========================>....] - ETA: 41s - loss: 4.1463 - acc: 0.2599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 342s 623us/step - loss: 4.1282 - acc: 0.2611\n",
      "\n",
      "Epoch 00019: loss improved from 4.15243 to 4.12820, saving model to model_chekpoints/weights-improvement-19-4.1282.hdf5\n",
      "Epoch 20/100\n",
      "254080/548030 [============>.................] - ETA: 3:03 - loss: 4.0832 - acc: 0.2640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 341s 622us/step - loss: 4.0832 - acc: 0.2650\n",
      "\n",
      "Epoch 00021: loss improved from 4.10543 to 4.08319, saving model to model_chekpoints/weights-improvement-21-4.0832.hdf5\n",
      "Epoch 22/100\n",
      " 58752/548030 [==>...........................] - ETA: 5:04 - loss: 4.0054 - acc: 0.2711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407424/548030 [=====================>........] - ETA: 1:27 - loss: 4.0290 - acc: 0.2699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 341s 622us/step - loss: 4.0257 - acc: 0.2702\n",
      "\n",
      "Epoch 00024: loss improved from 4.04324 to 4.02571, saving model to model_chekpoints/weights-improvement-24-4.0257.hdf5\n",
      "Epoch 25/100\n",
      "219008/548030 [==========>...................] - ETA: 3:24 - loss: 3.9767 - acc: 0.2744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510720/548030 [==========================>...] - ETA: 23s - loss: 3.9887 - acc: 0.2734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 341s 621us/step - loss: 3.9766 - acc: 0.2751\n",
      "\n",
      "Epoch 00027: loss improved from 3.99128 to 3.97665, saving model to model_chekpoints/weights-improvement-27-3.9766.hdf5\n",
      "Epoch 28/100\n",
      "288256/548030 [==============>...............] - ETA: 2:41 - loss: 3.9347 - acc: 0.2786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 341s 621us/step - loss: 3.9469 - acc: 0.2775\n",
      "\n",
      "Epoch 00029: loss improved from 3.96151 to 3.94693, saving model to model_chekpoints/weights-improvement-29-3.9469.hdf5\n",
      "Epoch 30/100\n",
      " 41728/548030 [=>............................] - ETA: 5:14 - loss: 3.8646 - acc: 0.2832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 341s 622us/step - loss: 3.9336 - acc: 0.2787\n",
      "\n",
      "Epoch 00030: loss improved from 3.94693 to 3.93359, saving model to model_chekpoints/weights-improvement-30-3.9336.hdf5\n",
      "Epoch 31/100\n",
      "338944/548030 [=================>............] - ETA: 2:10 - loss: 3.8933 - acc: 0.2819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 341s 622us/step - loss: 3.9099 - acc: 0.2811\n",
      "\n",
      "Epoch 00032: loss improved from 3.92006 to 3.90995, saving model to model_chekpoints/weights-improvement-32-3.9099.hdf5\n",
      "Epoch 33/100\n",
      " 81152/548030 [===>..........................] - ETA: 4:50 - loss: 3.8335 - acc: 0.2878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 341s 622us/step - loss: 3.8960 - acc: 0.2823\n",
      "\n",
      "Epoch 00033: loss improved from 3.90995 to 3.89601, saving model to model_chekpoints/weights-improvement-33-3.8960.hdf5\n",
      "Epoch 34/100\n",
      "355456/548030 [==================>...........] - ETA: 1:59 - loss: 3.8701 - acc: 0.2844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548030/548030 [==============================] - 343s 627us/step - loss: 3.8740 - acc: 0.2846\n",
      "\n",
      "Epoch 00035: loss improved from 3.88543 to 3.87397, saving model to model_chekpoints/weights-improvement-35-3.8740.hdf5\n",
      "Epoch 36/100\n",
      "548030/548030 [==============================] - 341s 623us/step - loss: 3.8651 - acc: 0.2854\n",
      "\n",
      "Epoch 00036: loss improved from 3.87397 to 3.86512, saving model to model_chekpoints/weights-improvement-36-3.8651.hdf5\n",
      "Epoch 37/100\n",
      "548030/548030 [==============================] - 341s 622us/step - loss: 3.8553 - acc: 0.2865\n",
      "\n",
      "Epoch 00037: loss improved from 3.86512 to 3.85526, saving model to model_chekpoints/weights-improvement-37-3.8553.hdf5\n",
      "Epoch 38/100\n",
      "548030/548030 [==============================] - 341s 623us/step - loss: 3.8448 - acc: 0.2875\n",
      "\n",
      "Epoch 00038: loss improved from 3.85526 to 3.84484, saving model to model_chekpoints/weights-improvement-38-3.8448.hdf5\n",
      "Epoch 39/100\n",
      "548030/548030 [==============================] - 341s 621us/step - loss: 3.8346 - acc: 0.2885\n",
      "\n",
      "Epoch 00039: loss improved from 3.84484 to 3.83462, saving model to model_chekpoints/weights-improvement-39-3.8346.hdf5\n",
      "Epoch 40/100\n",
      "548030/548030 [==============================] - 340s 621us/step - loss: 3.8256 - acc: 0.2894\n",
      "\n",
      "Epoch 00040: loss improved from 3.83462 to 3.82562, saving model to model_chekpoints/weights-improvement-40-3.8256.hdf5\n",
      "Epoch 41/100\n",
      "548030/548030 [==============================] - 340s 621us/step - loss: 3.8181 - acc: 0.2904\n",
      "\n",
      "Epoch 00041: loss improved from 3.82562 to 3.81808, saving model to model_chekpoints/weights-improvement-41-3.8181.hdf5\n",
      "Epoch 42/100\n",
      "548030/548030 [==============================] - 340s 621us/step - loss: 3.8104 - acc: 0.2910\n",
      "\n",
      "Epoch 00042: loss improved from 3.81808 to 3.81041, saving model to model_chekpoints/weights-improvement-42-3.8104.hdf5\n",
      "Epoch 43/100\n",
      "548030/548030 [==============================] - 340s 621us/step - loss: 3.8025 - acc: 0.2920\n",
      "\n",
      "Epoch 00043: loss improved from 3.81041 to 3.80251, saving model to model_chekpoints/weights-improvement-43-3.8025.hdf5\n",
      "Epoch 44/100\n",
      "548030/548030 [==============================] - 340s 621us/step - loss: 3.7948 - acc: 0.2925\n",
      "\n",
      "Epoch 00044: loss improved from 3.80251 to 3.79479, saving model to model_chekpoints/weights-improvement-44-3.7948.hdf5\n",
      "Epoch 45/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.7870 - acc: 0.2936\n",
      "\n",
      "Epoch 00045: loss improved from 3.79479 to 3.78696, saving model to model_chekpoints/weights-improvement-45-3.7870.hdf5\n",
      "Epoch 46/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.7801 - acc: 0.2946\n",
      "\n",
      "Epoch 00046: loss improved from 3.78696 to 3.78010, saving model to model_chekpoints/weights-improvement-46-3.7801.hdf5\n",
      "Epoch 47/100\n",
      "548030/548030 [==============================] - 340s 621us/step - loss: 3.7750 - acc: 0.2950\n",
      "\n",
      "Epoch 00047: loss improved from 3.78010 to 3.77502, saving model to model_chekpoints/weights-improvement-47-3.7750.hdf5\n",
      "Epoch 48/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.7671 - acc: 0.2960\n",
      "\n",
      "Epoch 00048: loss improved from 3.77502 to 3.76714, saving model to model_chekpoints/weights-improvement-48-3.7671.hdf5\n",
      "Epoch 49/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.7610 - acc: 0.2963\n",
      "\n",
      "Epoch 00049: loss improved from 3.76714 to 3.76096, saving model to model_chekpoints/weights-improvement-49-3.7610.hdf5\n",
      "Epoch 50/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.7549 - acc: 0.2971\n",
      "\n",
      "Epoch 00050: loss improved from 3.76096 to 3.75491, saving model to model_chekpoints/weights-improvement-50-3.7549.hdf5\n",
      "Epoch 51/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.7489 - acc: 0.2976\n",
      "\n",
      "Epoch 00051: loss improved from 3.75491 to 3.74886, saving model to model_chekpoints/weights-improvement-51-3.7489.hdf5\n",
      "Epoch 52/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.7427 - acc: 0.2984\n",
      "\n",
      "Epoch 00052: loss improved from 3.74886 to 3.74269, saving model to model_chekpoints/weights-improvement-52-3.7427.hdf5\n",
      "Epoch 53/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.7374 - acc: 0.2990\n",
      "\n",
      "Epoch 00053: loss improved from 3.74269 to 3.73741, saving model to model_chekpoints/weights-improvement-53-3.7374.hdf5\n",
      "Epoch 54/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.7326 - acc: 0.2987\n",
      "\n",
      "Epoch 00054: loss improved from 3.73741 to 3.73256, saving model to model_chekpoints/weights-improvement-54-3.7326.hdf5\n",
      "Epoch 55/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.7270 - acc: 0.3001\n",
      "\n",
      "Epoch 00055: loss improved from 3.73256 to 3.72698, saving model to model_chekpoints/weights-improvement-55-3.7270.hdf5\n",
      "Epoch 56/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.7211 - acc: 0.3001\n",
      "\n",
      "Epoch 00056: loss improved from 3.72698 to 3.72115, saving model to model_chekpoints/weights-improvement-56-3.7211.hdf5\n",
      "Epoch 57/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.7163 - acc: 0.3012\n",
      "\n",
      "Epoch 00057: loss improved from 3.72115 to 3.71633, saving model to model_chekpoints/weights-improvement-57-3.7163.hdf5\n",
      "Epoch 58/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.7113 - acc: 0.3020\n",
      "\n",
      "Epoch 00058: loss improved from 3.71633 to 3.71131, saving model to model_chekpoints/weights-improvement-58-3.7113.hdf5\n",
      "Epoch 59/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.7061 - acc: 0.3024\n",
      "\n",
      "Epoch 00059: loss improved from 3.71131 to 3.70613, saving model to model_chekpoints/weights-improvement-59-3.7061.hdf5\n",
      "Epoch 60/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.7022 - acc: 0.3027\n",
      "\n",
      "Epoch 00060: loss improved from 3.70613 to 3.70220, saving model to model_chekpoints/weights-improvement-60-3.7022.hdf5\n",
      "Epoch 61/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.6982 - acc: 0.3032\n",
      "\n",
      "Epoch 00061: loss improved from 3.70220 to 3.69819, saving model to model_chekpoints/weights-improvement-61-3.6982.hdf5\n",
      "Epoch 62/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.6915 - acc: 0.3042\n",
      "\n",
      "Epoch 00062: loss improved from 3.69819 to 3.69146, saving model to model_chekpoints/weights-improvement-62-3.6915.hdf5\n",
      "Epoch 63/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.6897 - acc: 0.3039\n",
      "\n",
      "Epoch 00063: loss improved from 3.69146 to 3.68969, saving model to model_chekpoints/weights-improvement-63-3.6897.hdf5\n",
      "Epoch 64/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.6839 - acc: 0.3049\n",
      "\n",
      "Epoch 00064: loss improved from 3.68969 to 3.68388, saving model to model_chekpoints/weights-improvement-64-3.6839.hdf5\n",
      "Epoch 65/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.6808 - acc: 0.3049\n",
      "\n",
      "Epoch 00065: loss improved from 3.68388 to 3.68080, saving model to model_chekpoints/weights-improvement-65-3.6808.hdf5\n",
      "Epoch 66/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.6754 - acc: 0.3056\n",
      "\n",
      "Epoch 00066: loss improved from 3.68080 to 3.67542, saving model to model_chekpoints/weights-improvement-66-3.6754.hdf5\n",
      "Epoch 67/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.6741 - acc: 0.3057\n",
      "\n",
      "Epoch 00067: loss improved from 3.67542 to 3.67406, saving model to model_chekpoints/weights-improvement-67-3.6741.hdf5\n",
      "Epoch 68/100\n",
      "548030/548030 [==============================] - 339s 619us/step - loss: 3.6697 - acc: 0.3063\n",
      "\n",
      "Epoch 00068: loss improved from 3.67406 to 3.66970, saving model to model_chekpoints/weights-improvement-68-3.6697.hdf5\n",
      "Epoch 69/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.6655 - acc: 0.3066\n",
      "\n",
      "Epoch 00069: loss improved from 3.66970 to 3.66550, saving model to model_chekpoints/weights-improvement-69-3.6655.hdf5\n",
      "Epoch 70/100\n",
      "548030/548030 [==============================] - 340s 620us/step - loss: 3.6631 - acc: 0.3071\n",
      "\n",
      "Epoch 00070: loss improved from 3.66550 to 3.66311, saving model to model_chekpoints/weights-improvement-70-3.6631.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "548030/548030 [==============================] - 313s 570us/step - loss: 3.6602 - acc: 0.3071\n",
      "\n",
      "Epoch 00071: loss improved from 3.66311 to 3.66019, saving model to model_chekpoints/weights-improvement-71-3.6602.hdf5\n",
      "Epoch 72/100\n",
      "548030/548030 [==============================] - 314s 573us/step - loss: 3.6548 - acc: 0.3080\n",
      "\n",
      "Epoch 00072: loss improved from 3.66019 to 3.65476, saving model to model_chekpoints/weights-improvement-72-3.6548.hdf5\n",
      "Epoch 73/100\n",
      "548030/548030 [==============================] - 313s 571us/step - loss: 3.6524 - acc: 0.3083\n",
      "\n",
      "Epoch 00073: loss improved from 3.65476 to 3.65239, saving model to model_chekpoints/weights-improvement-73-3.6524.hdf5\n",
      "Epoch 74/100\n",
      "548030/548030 [==============================] - 313s 571us/step - loss: 3.6484 - acc: 0.3090\n",
      "\n",
      "Epoch 00074: loss improved from 3.65239 to 3.64839, saving model to model_chekpoints/weights-improvement-74-3.6484.hdf5\n",
      "Epoch 75/100\n",
      "548030/548030 [==============================] - 313s 570us/step - loss: 3.6449 - acc: 0.3089\n",
      "\n",
      "Epoch 00075: loss improved from 3.64839 to 3.64489, saving model to model_chekpoints/weights-improvement-75-3.6449.hdf5\n",
      "Epoch 76/100\n",
      "548030/548030 [==============================] - 323s 590us/step - loss: 3.6428 - acc: 0.3093\n",
      "\n",
      "Epoch 00076: loss improved from 3.64489 to 3.64276, saving model to model_chekpoints/weights-improvement-76-3.6428.hdf5\n",
      "Epoch 77/100\n",
      "548030/548030 [==============================] - 329s 601us/step - loss: 3.6404 - acc: 0.3095\n",
      "\n",
      "Epoch 00077: loss improved from 3.64276 to 3.64037, saving model to model_chekpoints/weights-improvement-77-3.6404.hdf5\n",
      "Epoch 78/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6354 - acc: 0.3098\n",
      "\n",
      "Epoch 00078: loss improved from 3.64037 to 3.63536, saving model to model_chekpoints/weights-improvement-78-3.6354.hdf5\n",
      "Epoch 79/100\n",
      "548030/548030 [==============================] - 329s 601us/step - loss: 3.6335 - acc: 0.3096\n",
      "\n",
      "Epoch 00079: loss improved from 3.63536 to 3.63349, saving model to model_chekpoints/weights-improvement-79-3.6335.hdf5\n",
      "Epoch 80/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6312 - acc: 0.3105\n",
      "\n",
      "Epoch 00080: loss improved from 3.63349 to 3.63120, saving model to model_chekpoints/weights-improvement-80-3.6312.hdf5\n",
      "Epoch 81/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6273 - acc: 0.3110\n",
      "\n",
      "Epoch 00081: loss improved from 3.63120 to 3.62731, saving model to model_chekpoints/weights-improvement-81-3.6273.hdf5\n",
      "Epoch 82/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6258 - acc: 0.3110\n",
      "\n",
      "Epoch 00082: loss improved from 3.62731 to 3.62575, saving model to model_chekpoints/weights-improvement-82-3.6258.hdf5\n",
      "Epoch 83/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6221 - acc: 0.3113\n",
      "\n",
      "Epoch 00083: loss improved from 3.62575 to 3.62211, saving model to model_chekpoints/weights-improvement-83-3.6221.hdf5\n",
      "Epoch 84/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6200 - acc: 0.3115\n",
      "\n",
      "Epoch 00084: loss improved from 3.62211 to 3.62004, saving model to model_chekpoints/weights-improvement-84-3.6200.hdf5\n",
      "Epoch 85/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6166 - acc: 0.3116\n",
      "\n",
      "Epoch 00085: loss improved from 3.62004 to 3.61655, saving model to model_chekpoints/weights-improvement-85-3.6166.hdf5\n",
      "Epoch 86/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6147 - acc: 0.3121\n",
      "\n",
      "Epoch 00086: loss improved from 3.61655 to 3.61474, saving model to model_chekpoints/weights-improvement-86-3.6147.hdf5\n",
      "Epoch 87/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6123 - acc: 0.3127\n",
      "\n",
      "Epoch 00087: loss improved from 3.61474 to 3.61230, saving model to model_chekpoints/weights-improvement-87-3.6123.hdf5\n",
      "Epoch 88/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6111 - acc: 0.3127\n",
      "\n",
      "Epoch 00088: loss improved from 3.61230 to 3.61112, saving model to model_chekpoints/weights-improvement-88-3.6111.hdf5\n",
      "Epoch 89/100\n",
      "548030/548030 [==============================] - 329s 600us/step - loss: 3.6083 - acc: 0.3128\n",
      "\n",
      "Epoch 00089: loss improved from 3.61112 to 3.60826, saving model to model_chekpoints/weights-improvement-89-3.6083.hdf5\n",
      "Epoch 90/100\n",
      "412032/548030 [=====================>........] - ETA: 1:21 - loss: 3.5893 - acc: 0.3150"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, batch_size=128, epochs=100, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stoped at 89 for time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
