{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import collections\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename='all_songs.csv',\n",
    "              col='album',\n",
    "              col_value='In the Aeroplane Over the Sea'):\n",
    "    \n",
    "    df    = pd.read_csv('all_songs.csv')\n",
    "    df    = df.loc[df[col] == col_value]\n",
    "    songs = df['lyrics'].values\n",
    "    return songs\n",
    "\n",
    "def lyric_cleaner(songs):\n",
    "    lyric_tokens = []\n",
    "    for song in songs:\n",
    "        text = song.lower().replace(' n ', ' eol ').replace('[verse ', '[verse')\n",
    "        text = text.replace(\"'\", '').replace('-', ' ')\n",
    "        tokens = text.split()\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        tokens = [word.translate(table) for word in tokens]\n",
    "        lyric_tokens.append(tokens)\n",
    "    \n",
    "    return lyric_tokens\n",
    "\n",
    "def join_song_lyrics(lyric_tokens):\n",
    "    \n",
    "    joined_songs = []\n",
    "    \n",
    "    for song in lyric_tokens:\n",
    "        lyrics = ' '.join(song)\n",
    "        joined_songs.append(lyrics)\n",
    "        \n",
    "    return joined_songs\n",
    "\n",
    "def tokenizer(list_of_songs, tokenizer):\n",
    "    tokenizer = tokenizer\n",
    "    tokenizer.fit_on_texts(list_of_songs)\n",
    "    encoded_songs = tokenizer.texts_to_sequences(list_of_songs)\n",
    "    \n",
    "    return encoded_songs, tokenizer\n",
    "\n",
    "def find_longest_song(encoded_songs):\n",
    "    longest_song_size = 0\n",
    "    for song in encoded_songs:\n",
    "        if len(song) > longest_song_size:\n",
    "            longest_song_size = len(song)\n",
    "    return longest_song_size\n",
    "\n",
    "def index_to_word(tokenizer):\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    index_to_word_dict =  dict([(index, word) for word, index in tokenizer.word_index.items()])\n",
    "    return vocab_size, index_to_word_dict\n",
    "\n",
    "def pad_data(encoded_songs, max_length):\n",
    "    padded_songs = pad_sequences(encoded_songs, maxlen=max_length, padding='post', truncating='post')\n",
    "    return padded_songs\n",
    "\n",
    "def seqeuncer(padded_songs, length):\n",
    "    sequences = []\n",
    "    output = []\n",
    "\n",
    "    for song in padded_songs:\n",
    "        for i in range(length, (len(song))):\n",
    "            seq = song[i - length: i]\n",
    "            out = song[i]\n",
    "            sequences.append(seq)\n",
    "            output.append(out)\n",
    "            \n",
    "    return np.array(sequences), output\n",
    "\n",
    "def establish_model(vocab_size, seq_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def gen_seed(seqs):\n",
    "    seed_text = seqs[np.random.randint(0,len(seqs))]\n",
    "    while seed_text.all() == np.array([  0, 0,  0, 0, 0, 0, 0, 0, 0, 0]).all():\n",
    "        seed_text = seqs[np.random.randint(0,len(seqs))]\n",
    "    return seed_text\n",
    "\n",
    "def generate_seq(model,\n",
    "                 tokenizer,\n",
    "                 seq_length,\n",
    "                 seqs,\n",
    "                 n_words=1000):\n",
    "    \n",
    "    seed_text = gen_seed()\n",
    "    start = [reverse_dict[index] for index in seed_text]\n",
    "    print('start: ', start)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for _ in range(n_words):\n",
    "        encoded = pad_sequences([seed_text], maxlen=seq_length, truncating='pre')\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        if yhat == 0:\n",
    "            pass\n",
    "        else:\n",
    "            word = reverse_dict[yhat[0]]\n",
    "        seed_text = np.append(seed_text, yhat)\n",
    "        seed_text = seed_text[-10:]\n",
    "        result.append(word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e90ee1ed0fba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sequences' is not defined"
     ]
    }
   ],
   "source": [
    "sequences[0][0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-270dd209b8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(filename='all_songs.csv', col='artist', col_value='The Decemberists')\n",
    "\n",
    "token_lyrics = lyric_cleaner(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for song in token_lyrics:\n",
    "    song.append('eos')\n",
    "    for word in song:\n",
    "        words.append(word)\n",
    "\n",
    "word_count = collections.Counter(words)\n",
    "\n",
    "len_vocab = 2500\n",
    "\n",
    "most_common = word_count.most_common(n=len_vocab)\n",
    "\n",
    "vocab = []\n",
    "for word, count in most_common:\n",
    "    vocab.append(word)\n",
    "\n",
    "word_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "# word_to_index['eos'] = 0\n",
    "word_to_index['unknown'] = len(vocab)\n",
    "\n",
    "index_to_word = dict([(index, word) for word, index in word_to_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('the_decemberists_word_to_index', 'wb') as f:\n",
    "    pickle.dump(word_to_index, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('the_decemberists_index_to_word', 'wb') as f:\n",
    "    pickle.dump(index_to_word, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_words = [word_to_index[word] if word in word_to_index else word_to_index['unknown'] for word in words]\n",
    "\n",
    "length = 25 + 1\n",
    "sequences = []\n",
    "for i in range(length, len(encoded_words)):\n",
    "    seq = encoded_words[i-length:i]\n",
    "#     line = ' '.join(seq)\n",
    "    sequences.append(seq)\n",
    "\n",
    "n_patterns = len(sequences)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "y = to_categorical(y)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len_vocab, 50, input_length=25))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(len_vocab, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"model_checkpoints/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3cde17ea2a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=100, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_seed(sequences):\n",
    "    seed_text = sequences[np.random.randint(0,len(sequences))]\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_text.all() == np.array([  0, 0,  0, 0, 0, 0, 0, 0, 0, 0]).all():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_text = sequences[np.random.randint(0,len(sequences))][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139,   0,   2, ...,  11, 396,   1],\n",
       "       [  0,   2, 396, ..., 396,   1, 300],\n",
       "       [  2, 396,   1, ...,   1, 300, 950],\n",
       "       ...,\n",
       "       [269,   4,   2, ...,  24,  63, 187],\n",
       "       [  4,   2,   5, ...,  63, 187,  19],\n",
       "       [  2,   5, 860, ..., 187,  19, 695]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.expand_dims(X[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected embedding_5_input to have shape (25,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-fe8a05248961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \"\"\"\n\u001b[1;32m   1137\u001b[0m         proba = self.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1138\u001b[0;31m                              steps=steps)\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1025\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1823\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1824\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1825\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected embedding_5_input to have shape (25,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.predict_classes(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.full(25, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22,  67,   0,   2,  11,   1, 225,  25, 589, 335,   0,  45,   5,\n",
       "        93, 119,  12,  49, 244, 188,   0,  13,  28,   3, 412, 156,   0])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_songs(model, sequences, seq_length, reverse_dictionary, n_words=1000, seed_num=2018\n",
    "#                    generate_random=True\n",
    "                  ):\n",
    "    seed_text = sequences[seed_num]\n",
    "#     seed_text = gen_seed(sequences=sequences)[:seq_length]\n",
    "    start = [reverse_dictionary[index] for index in seed_text]\n",
    "    print('start: ', ' '.join(start))\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for _ in range(n_words):\n",
    "        in_text = np.expand_dims(seed_text, axis=0)\n",
    "        yhat = model.predict_classes(in_text, verbose=0)\n",
    "        if yhat == 2500:\n",
    "            word = words.words()[np.random.randint(0,len(words.words()))]\n",
    "        else:\n",
    "            word = reverse_dictionary[yhat[0]]\n",
    "        seed_text = np.append(seed_text, yhat)\n",
    "        seed_text = seed_text[-seq_length:]\n",
    "        result.append(word)\n",
    "            \n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  postman do you have a letter for me eol a letter for me eol from my own true love eol lost at sea eol lost\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'at sea eol mr postman do you have a letter for me eol mr postman do you have a letter for me eol chorus eol and try one and try two eol guess it always comes down to eol alright its okay eol guess it always comes down in wait for symmetry eol and were was a county lineman eol on a high line on his arm eol arms but i take us jimmy row eol oh never begin eol i will hang my love my love eol my bones fill unknown eol go to shoulder eol youll not betray us to me eol clawing at the ceiling eol of my grave eol i am the only writer off the jewess and the brow eol i have unknown that i am you here eol didnt i didnt i didnt i eol my life dont see thats unknown a unknown drowned eol over you eol but something went limp beneath the wind eol and all the waves will be here eol wont quell my want for love eol and i may swoon from all this swelling eol but i wont want for love eol william colin meloy eol oh my own true love eol two away unknown in unknown eol go down down eol go by dirigible eol well do night e eol the pilgrims pills and tourists here eol dont fill our mouths with cinnamon eol hear her clothes fall eol how i eol i was waiting eol oh night eol its unknown eyes oh eol all the unknown of unknown wall where we were there eol come of gold and silver eol i dont row if only that be home eol and lady never really unknown eol and all that the taiga eol youll unknown and more eol all dolled up in a pushcart ship to kick this unknown eol looking deep of the bus mall eol oh ooh oh eol oh as the hazards of love eol 2x eol it never seemed so strange eol when we dole edgar watson in his pushcart ship hard eol who figured im been here with my falling eol i am tortured eol its a world you happened stones and hog in the foyer eol you was found into your bones eol and youre standing home jimmy eol and curls eol everybody met to her bones eol it was a perfect crime eol verse2 eol i got a gun i got a way to the unknown eol is the sun of california heart eol will take your belly as a little hungry eol but i got a mock up in the fold eol verse2 eol i got a childhood in been in town eol william colin meloy eol oh the hazards of love eol youll learn soon enough the rooftop plays something familiar eol all the war came upon our unknown eol a unknown daughter eol all the war came unknown in unknown eol hes keep a bitter sting eol chorus eol how there in a bathroom stall off the boys papers eol refrain eol oh oh eol oh hoh hoh eol lah di dah di dah eol ah hah hoh oho eol chorus eol my true love went riding went one eol in a chemical chemical kind eol as the shankill butchers wanna cut you down eol well all our skin was all in the day eol a jetty caught in overhanging trees eol among the bones of the embassy of her fingers eol annabelle where the shankill butchers ride tonight eol bring back in unknown eol hey hey hey hey hey eol hey hey hey hey hey eol and this is the words broke unknown eol i got the mob boss bought eol the only son way to unknown eol dad its our city of the labor guy all round eol in the snowy wild down eol on the old men would tattered the war eol come a hole thats me broke eol and all i heard that your skin apart eol made at the unknown unknown raised eol take up my got to her bones eol it was a little years arms eol theyre made all the wind eol and how they held at my heart eol it never leave a unknown to you eol and isnt it careful as i am repaid my hands eol look at me eol theres a cartoon and hold salt mine eol like a chew into kind at symmetry eol and i will resume me seems a baby boy eol and the ricks and the racks and the run eol what do we do eol its foregone eol its a shallow little world eol and i must push my barrow boy of they eol we know to we knew our bodies was in our fingers eol verse2 eol what do we do how what blow eol and henry can one acres furrowed in the day eol fell away down for unknown eol still left their legs stones and valley chasers eol c’est a perfect paramour eol for it’s the taiga of water wall where shake of sea eol verse2 eol the unknown unknown battle with the unknown eol though i wont betray eol unknown unknown eol what unknown the unknown eol come the archers eol of hell eol this is why eol why we fight eol why we lie awake eol and i was meant for the stage eol i was a toast to the door eol and now its with a baby in and within our unknown eol no more and see and absolute eos say goodnight boys goodnight eol i got a seedling of an fingers eol trying to go on a bed of unknown before eol swore to sea by unknown unknown eol unknown and moribund and candlelight eol chorus eol verse3 eol i figured i had to change your eyes eol come unknown of the unknown eol and you were made for me eol its i 4 u and'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_songs(\n",
    "    model=model,\n",
    "    sequences=X,\n",
    "    seq_length=25,\n",
    "    reverse_dictionary=index_to_word,\n",
    "    n_words=1000, \n",
    "    file_name='the_decemberists.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  rolls down the drain eol oh what a lonely thing eol in a lonely drain eol chorus eol july july july eol it never seemed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'so strange eol july july july eol it never seemed so eol it never seemed so strange eol fifteen picking on your weeping bother eol the lash unknown fifteen shins eol you you wont change you down eol and the sun breaks to no youre a common collective eol i am imprinted upon your stars eol and raise a glass to unknown of the season eol witness to the old main drag eol down by the old main drag eol down by the water and eol down her got shaking eol in a bloodlines eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love me let me go eol and if you dont love'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_songs(\n",
    "    model=model,\n",
    "    sequences=X,\n",
    "    seq_length=25,\n",
    "    reverse_dictionary=index_to_word,\n",
    "    n_words=1000, \n",
    "    file_name='the_decemberists.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  so you bend back and shake at the frame eol of the frame you made eol but dont you shake alone eol please avery come\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'home eol head strong you and let me see eol its calm a legs were between hard eol a soft on the heads eol and youre a common way to go eol get to all too slow eol but ill shake the uncle daughter eol chorus eol and then she came here and calm and easy and willow me unknown eol hey hey hey as the old main lioness eol and we hold in our sigh eol dont carry it all dont carry it all eol hes keep on stealin eol if you for you and you were made for me eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if you ever make it to ten you wont make it again eol and if'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_songs(\n",
    "    model=model,\n",
    "    sequences=X,\n",
    "    seq_length=25,\n",
    "    reverse_dictionary=index_to_word,\n",
    "    n_words=1000, \n",
    "    file_name='the_decemberists.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_100 = models.load_model('model_checkpoints/weights-improvement-100-0.5531.hdf5')\n",
    "model_75  = models.load_model('model_checkpoints/weights-improvement-75-0.9800.hdf5')\n",
    "model_50  = models.load_model('model_checkpoints/weights-improvement-50-1.6432.hdf5')\n",
    "model_25  = models.load_model('model_checkpoints/weights-improvement-25-2.8392.hdf5')\n",
    "model_1   = models.load_model('model_checkpoints/weights-improvement-01-5.8760.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n",
      "model_1:\n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol \n",
      " eol eol\n",
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n",
      "model_25:\n",
      " full \n",
      " gazing and the lulling of the cafe bars \n",
      " the bullets of the perfect crime \n",
      " chorus \n",
      " and i will hang my head hang my head hang my head hang my head hang my head low \n",
      " and i dont swoon from build your wall \n",
      " hold to make your precious collective \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone \n",
      " its foregone\n",
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n",
      "model_50:\n",
      " eol over the unknown \n",
      " and the wanting comes in waves \n",
      " and the wanting comes in waves \n",
      " thatll teach him \n",
      " columbine columbine \n",
      " please see your eyes fill unknown provide me \n",
      " no more in the wind \n",
      " i spied in sable \n",
      " i got the remedy to your heart \n",
      " but oh it so beginning \n",
      " if i am a chimney happy with a unknown unknown \n",
      " and the unknown came \n",
      " and the wanting comes in waves \n",
      " thatll teach him \n",
      " columbine \n",
      " the gymnast days in deep \n",
      " wholl plane the unknown is\n",
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n",
      "model_75:\n",
      " eol a million early sway \n",
      " and the side roll down \n",
      " the season rubs me wrong \n",
      " the summer swells anon \n",
      " so knock me down tear me up \n",
      " but i \n",
      " i could just grab you by the nape of your neck \n",
      " well all come praise the mattress and tumbled to sleep \n",
      " this is solution and the glimmer \n",
      " hear \n",
      " this is why \n",
      " this is why we fight \n",
      " come hell \n",
      " come hell \n",
      " come hell \n",
      " i got a perfect crime \n",
      " well pull a unknown on track \n",
      " ive months\n",
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n",
      "model_100:\n",
      " eol its our wicked clinging to the breeze \n",
      " down by the old town \n",
      " the prior carve the wrong tan \n",
      " of thirty two gently clenching wrinkled little dah driver \n",
      " back in dimes upon your ventricles apart \n",
      " this is the story of walls for the rain \n",
      " im deep \n",
      " we laid our calling guard bright cocaine \n",
      " and we must push my barrow all unfurled \n",
      " stretched out like well go home again \n",
      " curse this daughters will turn this unknown and unknown now \n",
      " julie better to the unknown wild \n",
      " and all the unknown\n"
     ]
    }
   ],
   "source": [
    "model_names = ['model_1', 'model_25', 'model_50', 'model_75', 'model_100']\n",
    "for count, model in enumerate([model_1, model_25, model_50, model_75, model_100]):\n",
    "    name = model_names[count]\n",
    "    generated_lyrics = generate_songs(\n",
    "                            model=model,\n",
    "                            sequences=X,\n",
    "                            seq_length=25,\n",
    "                            reverse_dictionary=index_to_word,\n",
    "                            n_words=100, \n",
    "                            file_name='the_decemberists.txt'\n",
    "                        )\n",
    "    generated_lyrics = generated_lyrics.replace(' eol ', ' \\n ').replace(' eos ', ' \\n\\n\\n ')\n",
    "    \n",
    "    with open\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(name + ':\\n', generated_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n",
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n",
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n",
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n",
      "start:  so long eol and all the stars were crashing round eol as i laid eyes on what id found eol it was a white crane\n"
     ]
    }
   ],
   "source": [
    "model_names = ['model_1', 'model_25', 'model_50', 'model_75', 'model_100']\n",
    "for count, model in enumerate([model_1, model_25, model_50, model_75, model_100]):\n",
    "    name = model_names[count]\n",
    "    generated_lyrics = generate_songs(\n",
    "                            model=model,\n",
    "                            sequences=X,\n",
    "                            seq_length=25,\n",
    "                            reverse_dictionary=index_to_word,\n",
    "                            n_words=100\n",
    "                        )\n",
    "    \n",
    "    generated_lyrics = generated_lyrics.replace(' eol ', ' \\n ').replace(' eos ', ' \\n\\n\\n ')\n",
    "    \n",
    "    file_name='the_decemberists_seed_num2018.txt'\n",
    "    \n",
    "    with open(file_name, 'a+') as f:\n",
    "        print(name + ':\\n', generated_lyrics + '\\n\\n\\n', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_cleaner(text_in):\n",
    "    text_in = text_in.lower().replace(' n ', ' eol ').replace('[verse ', '[verse')\n",
    "    text_in = text_in.replace(\"'\", '').replace('-', ' ')\n",
    "    tokens = text_in.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [word.translate(table) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "def generate_seed_text_from_input():\n",
    "    \n",
    "    input_text = input('Type what you want here.')\n",
    "    \n",
    "    seed_text = input_cleaner(input_text)\n",
    "    \n",
    "    seed_text = [word_to_index[word] if word in word_to_index else word_to_index['unknown'] for word in seed_text]\n",
    "    \n",
    "    seed_text = pad_sequences([seed_text], maxlen=25, value=2500)\n",
    "    \n",
    "    print('Rendering text as lyrics...')\n",
    "    \n",
    "    return seed_text, input_text\n",
    "\n",
    "\n",
    "\n",
    "def generate_song_from_input(model, seq_length, reverse_dictionary, n_words, seed_text):\n",
    "    \n",
    "    print('Writing new song')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    seed_text = np.squeeze(seed_text, axis=0)\n",
    "    \n",
    "    for _ in range(n_words):\n",
    "        in_text = np.expand_dims(seed_text, axis=0)\n",
    "        yhat = model.predict_classes(in_text)\n",
    "        if yhat == 2500:\n",
    "            word = words.words()[np.random.randint(0,len(words.words()))]\n",
    "        else:\n",
    "            word = reverse_dictionary[yhat[0]]\n",
    "        seed_text = np.append(seed_text, yhat)\n",
    "        seed_text = seed_text[-seq_length:]\n",
    "        result.append(word)\n",
    "           \n",
    "    return ' '.join(result)\n",
    "\n",
    "def generate_new_song():\n",
    "    model = model_50\n",
    "    seq_length = 25\n",
    "    reverse_dictionary = index_to_word\n",
    "    n_words = int(input('How many words?'))\n",
    "    \n",
    "    seed_text, input_text = generate_seed_text_from_input()\n",
    "    \n",
    "    lyrics = generate_song_from_input(model, seq_length, reverse_dictionary, n_words, seed_text)\n",
    "    \n",
    "    lyrics = lyrics.replace(' eol ', ' \\n ').replace(' eos ', ' \\n\\n\\n ')\n",
    "    \n",
    "    complete_song = input_text + '\\n' + lyrics\n",
    "    \n",
    "    print('New song finished!')\n",
    "    \n",
    "    return complete_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many words?500\n",
      "Type what you want here.yonder mountains knew the truth but could not speak\n",
      "Rendering text as lyrics...\n",
      "Writing new song\n",
      "New song finished!\n"
     ]
    }
   ],
   "source": [
    "new_song = generate_new_song()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yonder mountains knew the truth but could not speak\n",
      "that superaccessory and hummocky \n",
      " lost out hammering \n",
      " parapegma taking compress in white and is wait for me \n",
      " Rabbinic and sunfisher and puriri and rufflike and tain and vervel and repine and scream and willow me in stardom \n",
      " because the slubby of the snavel and walls in the Xiphias \n",
      " and the wanting comes in waves \n",
      " and the ricks and the racks and the run \n",
      " and i am a brawn \n",
      " i got the cavalry captain \n",
      " i am the remedy to the Turkophobist \n",
      " and if you dont love me let me go \n",
      " and if you dont love me let me go \n",
      " thatll teach him \n",
      " columbine columbine \n",
      " the pearliness of the rollicksome of the circle k \n",
      " so the wanting comes in waves \n",
      " thatll teach him \n",
      " and a queen all over themselves \n",
      " we laid edgar styrofoam \n",
      " to a lone concertina they drank in tow \n",
      " in the water of the seine \n",
      " it’ll eat a levigate wall and quiet \n",
      " like a heads \n",
      " among the bombs of broth wall where the infiniteness of the freeway \n",
      " and the wanting comes in waves \n",
      " thatll teach him \n",
      " and a families cant all over \n",
      " eol its foregone \n",
      " its foregone \n",
      " its a shallow little frame \n",
      " and what you render me up boy \n",
      " and i am a writer writer of fictions \n",
      " my bones \n",
      " and oh it and no i brought you and and i wont do \n",
      " if i am waiting \n",
      " should i could afford \n",
      " guess it always comes of chaparral now \n",
      " verse1 \n",
      " ramblin \n",
      " of the bus mall \n",
      " and a rake \n",
      " i got a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a perfect crime \n",
      " c’est a\n"
     ]
    }
   ],
   "source": [
    "print(new_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = load_data(filename='all_songs.csv', col='is_folk', col_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5365,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5365, 18)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['is_folk'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_text, input_text = generate_seed_text_from_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eol april more and iliococcygeal and interstriation and scream and willow eos from eos eol its a shallow little frame eol and its a unbacked to the paronomasian eol and i am a brawn eol i got the cavalry captain eol i am a brawn eol i am a writer of a politicalize irradiate eol and the ricks and the racks and the run eol and i am a brawn eol i got the cavalry captain eol i am the remedy to the dispossess eol and if you dont with eos let eos go eol and if you dont with'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_song = generate_song_from_input(model_75, 25, reverse_dictionary=index_to_word, n_words=100, seed_text=seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
